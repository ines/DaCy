{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd02136a9c3637fd160483224d7922e48bf03b650be5dff26724a0c1f8d1279953b",
   "display_name": "Python 3.8.8 64-bit ('NLP': virtualenvwrapper)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# DaCy and Sentiment\n",
    "DaCy currently does not include its own tools for sentiment extraction, but a couple of good tools already exists. Thus DaCy wraps these in the DaCy framework."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install git+https://github.com/KennethEnevoldsen/DaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when running from a downloaded version of the github you will need to move back one folder.\n",
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dacy\n",
    "import spacy"
   ]
  },
  {
   "source": [
    "# Overiew of Models\n",
    "--- \n",
    "\n",
    "| Name  | Creator   | Domain   | Output Type  | Model Type | \n",
    "|:---|:-------------|:------|:------|:------|\n",
    "| Senda | Ekstra Bladet  | Twitter  | `['postive', 'neutral', 'negative']` | Danish Transformer v2 by BotXO | \n",
    "| BertTone | DaNLP  | Europarl and Twitter  | `['postive', 'neutral', 'negative'] and ['subjective', 'objective']` | Danish Transformer v2 by BotXO | \n",
    "| BertEmotion | DaNLP | Social Media   | `[\"Emotional\", \"No emotion\"] and  [\"Glæde/Sindsro\", \"Tillid/Accept\", ... ]` | Danish Transformer v2 by BotXO | \n",
    "| DaVader | Sentida    | Microblogs and Social media  | `Polarity score (continuous)`     | Rule-based | \n",
    "\n",
    "*Note* that DaVader is a variation of Sentida and not the original implementation.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Senda\n",
    "\n",
    "Senda is a model trained by Ektra Bladet on a [danish Twitter corpus](https://github.com/alexandrainst/danlp/blob/master/docs/docs/tasks/sentiment_analysis.md) tagged for polarity. Compared to the BertTone model senda should have a higher performance on Twitter data. Read more about `senda` on its associated [github](https://github.com/ebanalyse/senda).\n",
    "\n",
    "Here I will show a simple use case of the model and how to add it to your pipeline:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"da\")\n",
    "nlp = dacy.sentiment.add_senda(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "positive\n{'prop': array([0.063, 0.169, 0.768], dtype=float32), 'labels': ['negative', 'neutral', 'positive']}\nnegative\n{'prop': array([0.625, 0.273, 0.102], dtype=float32), 'labels': ['negative', 'neutral', 'positive']}\nneutral\n{'prop': array([0.041, 0.869, 0.09 ], dtype=float32), 'labels': ['negative', 'neutral', 'positive']}\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Sikke en dejlig dag det er i dag\", \"Sikke noget forfærdeligt møjvejr det er i dag\", \"FC København og Brøndby IF i duel om mesterskabet\"]\n",
    "\n",
    "docs = nlp.pipe(texts)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc._.polarity)\n",
    "    print(doc._.polarity_prop)"
   ]
  },
  {
   "source": [
    "## BertTone\n",
    "---\n",
    "\n",
    "BertTone is a model trained by DaNLP, actually it is two. One for classification of polarity (whether a sentence is positive, negative or neutral) and subjectivity (whether a text is subjective or not).\n",
    "\n",
    "To read more about BertTone as well as its performance matched against other models see DaNLP's [GitHub](https://github.com/alexandrainst/danlp/blob/master/docs/docs/tasks/sentiment_analysis.md).\n",
    "\n",
    "Here I will show a simple use case of both models. Furthermore if you wish to inspect the TransformerData to see e.g. the used wordpieces you check out the `doc._.berttone_subj_trf_data` or `doc._.berttone_pol_trf_data`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model bert.subjective exists in /Users/au561649/.danlp/bert.subjective\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"da\")\n",
    "nlp = dacy.sentiment.add_berttone_subjectivity(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "objective\n{'prop': array([1., 0.], dtype=float32), 'labels': ['objective', 'subjective']}\nsubjective\n{'prop': array([0., 1.], dtype=float32), 'labels': ['objective', 'subjective']}\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Analysen viser, at økonomien bliver forfærdelig dårlig\", \n",
    "         \"Jeg tror alligvel, det bliver godt\"]\n",
    "\n",
    "docs = nlp.pipe(texts)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc._.subjectivity)\n",
    "    print(doc._.subjectivity_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model bert.polarity exists in /Users/au561649/.danlp/bert.polarity\n",
      "negative\n",
      "{'prop': array([0.002, 0.008, 0.99 ], dtype=float32), 'labels': ['positive', 'neutral', 'negative']}\n",
      "positive\n",
      "{'prop': array([0.854, 0.146, 0.001], dtype=float32), 'labels': ['positive', 'neutral', 'negative']}\n"
     ]
    }
   ],
   "source": [
    "nlp = dacy.sentiment.add_berttone_polarity(nlp)\n",
    "\n",
    "docs = nlp.pipe(texts)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc._.polarity)\n",
    "    print(doc._.polarity_prop)"
   ]
  },
  {
   "source": [
    "BertEmotion\n",
    "---\n",
    "\n",
    "Siliar to BertTone is a BertEmoiton is a model trained by DaNLP, actually it is also two. One for classifying whether a text is emotionally laden or not, and one for emotion classification using. The possible emotions to classify from is:\n",
    "\n",
    "- \"Glæde/Sindsro\"\n",
    "- \"Tillid/Accept\"\n",
    "- \"Forventning/Interrese\"\n",
    "- \"Overasket/Målløs\"\n",
    "- \"Vrede/Irritation\"\n",
    "- \"Foragt/Modvilje\"\n",
    "- \"Sorg/trist\"\n",
    "- \"Frygt/Bekymret\"\n",
    "\n",
    "Their transformerData can be accessed using `bertemotion_laden_trf_data` for the model whether a text is emotionally laden and `bertemotion_emo_trf_data` for the model predicting emotion. Similarly to above you can always use the `*_prop` prefix to extract the probabilities of each label."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model bert.noemotion exists in /Users/au561649/.danlp/bert.noemotion\n",
      "Model bert.emotion exists in /Users/au561649/.danlp/bert.emotion\n"
     ]
    }
   ],
   "source": [
    "nlp = dacy.sentiment.add_bertemotion_laden(nlp)  # whether a text is emotionally laden\n",
    "nlp = dacy.sentiment.add_bertemotion_emo(nlp)    # what emotion is portrayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Emotional\n\t Tillid/Accept\nEmotional\n\t Tillid/Accept\nEmotional\n\t Sorg/trist\nEmotional\n\t Frygt/Bekymret\nEmotional\n\t Sorg/trist\nEmotional\n\t Overasket/Målløs\nEmotional\n\t Forventning/Interrese\nEmotional\n\t Foragt/Modvilje\n"
     ]
    }
   ],
   "source": [
    "texts = ['bilen er flot', \n",
    "         'jeg ejer en rød bil og det er en god bil', \n",
    "         'jeg ejer en rød bil men den er gået i stykker', \n",
    "         \"Ifølge TV udsendelsen så bliver vejret skidt imorgen\",  \n",
    "         \"Fuck jeg hader bare Hitler. Han er bare så FUCKING træls!\",\n",
    "         \"Har i set at Tesla har landet en raket på månen? Det er vildt!!\",\n",
    "         \"Nu må vi altså få ændret noget\",\n",
    "         \"En sten kan ikke flyve. Morlille kan ikke flyve. Ergo er morlille en sten!\"]\n",
    "\n",
    "docs = nlp.pipe(texts)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc._.laden)\n",
    "    print(\"\\t\", doc._.emotion)"
   ]
  },
  {
   "source": [
    "Den opmærksomme person, ville med rette undre sig over outputtet altid er emotional. Det gjorde jeg også selv så har forsøgt med en lang række eksempler. Desværre har jeg endnu ikke fundet et som giver et \"No emotion\"-tagget. Har indberettet dette som en fejl til DaNLP's [GitHub](https://github.com/alexandrainst/danlp/issues/122). Dog som det ser ud pt. vil jeg ikke anbefale at bruge modellen i praktiske applikationer. Det ses særligt tydeligt i det næste output som også printer sandsynlighederne:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'prop': array([1., 0.], dtype=float32), 'labels': ['Emotional', 'No emotion']}\n{'prop': array([0.831, 0.169], dtype=float32), 'labels': ['Emotional', 'No emotion']}\n{'prop': array([1., 0.], dtype=float32), 'labels': ['Emotional', 'No emotion']}\n{'prop': array([1., 0.], dtype=float32), 'labels': ['Emotional', 'No emotion']}\n{'prop': array([1., 0.], dtype=float32), 'labels': ['Emotional', 'No emotion']}\n{'prop': array([1., 0.], dtype=float32), 'labels': ['Emotional', 'No emotion']}\n{'prop': array([0.999, 0.001], dtype=float32), 'labels': ['Emotional', 'No emotion']}\n{'prop': array([0.997, 0.003], dtype=float32), 'labels': ['Emotional', 'No emotion']}\n"
     ]
    }
   ],
   "source": [
    "docs = nlp.pipe(texts)\n",
    "for doc in docs:\n",
    "    print(doc._.laden_prop)"
   ]
  },
  {
   "source": [
    "## DaVader\n",
    "\n",
    "---\n",
    "\n",
    "DaVader is a Danish Sentiment model developing using [Vader](https://github.com/fnielsen/afinn) and the dictionary list of [SentiDa](https://github.com/guscode/sentida) and [AFINN](https://github.com/fnielsen/afinn). This adaption is developed by Center for Humanities Computing Aarhus and by the author of this package. It is a lexicon and rule-based sentiment analysis tool which predict sentiment valence - the degree to which a text is positive or negative - as opposed to BertTone which simply predict whether or not it is.\n",
    "\n",
    "An additional advantage of it being rule-based is that it is transparent (the entire lexion can be found in the sentiment folder) and very fast compared to transformer-based approaches."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "from dacy.sentiment import da_vader_getter\n",
    "\n",
    "Doc.set_extension(\"vader_da\", getter=da_vader_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'neg': 0.0, 'neu': 0.36, 'pos': 0.64, 'compound': 0.7456}\n{'neg': 0.088, 'neu': 0.395, 'pos': 0.518, 'compound': 0.674}\n{'neg': 0.1, 'neu': 0.688, 'pos': 0.212, 'compound': 0.0772}\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "texts = ['Jeg er så glad', 'jeg ejer en rød bil og det er en god bil', 'jeg ejer en rød bil men den er gået i stykker']\n",
    "\n",
    "docs = nlp.pipe(texts)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc._.vader_da)"
   ]
  },
  {
   "source": [
    "If you are have never used a VADER model before I suggest you read the [\"about the scoring\"](https://github.com/cjhutto/vaderSentiment#about-the-scoring) on the website for the original (English) VADER implementation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}